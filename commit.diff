diff --git a/main.py b/main.py
index e828ea0..5a1d464 100644
--- a/main.py
+++ b/main.py
@@ -20,14 +20,15 @@ import torchvision.models as models
 import torchvision.transforms as transforms
 from torch.optim.lr_scheduler import StepLR
 from torch.utils.data import Subset
+from torch.utils.tensorboard import SummaryWriter
 
 model_names = sorted(name for name in models.__dict__
     if name.islower() and not name.startswith("__")
     and callable(models.__dict__[name]))
 
 parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')
-parser.add_argument('data', metavar='DIR', nargs='?', default='imagenet',
-                    help='path to dataset (default: imagenet)')
+parser.add_argument('data', metavar='DIR', nargs='?', default='/data/bitahub/Tiny-ImageNet',
+                    help='path to dataset (default: /data/bitahub/Tiny-ImageNet)')
 parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet18',
                     choices=model_names,
                     help='model architecture: ' +
@@ -35,7 +36,7 @@ parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet18',
                         ' (default: resnet18)')
 parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',
                     help='number of data loading workers (default: 4)')
-parser.add_argument('--epochs', default=90, type=int, metavar='N',
+parser.add_argument('--epochs', default=15, type=int, metavar='N',
                     help='number of total epochs to run')
 parser.add_argument('--start-epoch', default=0, type=int, metavar='N',
                     help='manual epoch number (useful on restarts)')
@@ -104,6 +105,8 @@ def main():
 
     args.distributed = args.world_size > 1 or args.multiprocessing_distributed
 
+    
+
     if torch.cuda.is_available():
         ngpus_per_node = torch.cuda.device_count()
     else:
@@ -143,6 +146,11 @@ def main_worker(gpu, ngpus_per_node, args):
     else:
         print("=> creating model '{}'".format(args.arch))
         model = models.__dict__[args.arch]()
+        
+    # Modify the last layer of the model to have 200 output dimensions
+    num_features = model.fc.in_features
+    model.fc = nn.Linear(num_features, 200)
+        
 
     if not torch.cuda.is_available() and not torch.backends.mps.is_available():
         print('using CPU, this will be slow')
@@ -202,8 +210,9 @@ def main_worker(gpu, ngpus_per_node, args):
     if args.resume:
         if os.path.isfile(args.resume):
             print("=> loading checkpoint '{}'".format(args.resume))
+            model = nn.DataParallel(model)
             if args.gpu is None:
-                checkpoint = torch.load(args.resume)
+                checkpoint = torch.load(args.resume, map_location=torch.device('cpu'))
             elif torch.cuda.is_available():
                 # Map model to be loaded to specified single gpu.
                 loc = 'cuda:{}'.format(args.gpu)
@@ -213,7 +222,7 @@ def main_worker(gpu, ngpus_per_node, args):
             if args.gpu is not None:
                 # best_acc1 may be from a checkpoint from a different GPU
                 best_acc1 = best_acc1.to(args.gpu)
-            model.load_state_dict(checkpoint['state_dict'])
+            model.load_state_dict(checkpoint['state_dict'], False)
             optimizer.load_state_dict(checkpoint['optimizer'])
             scheduler.load_state_dict(checkpoint['scheduler'])
             print("=> loaded checkpoint '{}' (epoch {})"
@@ -225,31 +234,34 @@ def main_worker(gpu, ngpus_per_node, args):
     # Data loading code
     if args.dummy:
         print("=> Dummy data is used!")
-        train_dataset = datasets.FakeData(1281167, (3, 224, 224), 1000, transforms.ToTensor())
-        val_dataset = datasets.FakeData(50000, (3, 224, 224), 1000, transforms.ToTensor())
+        train_dataset = datasets.FakeData(1281167, (3, 64, 64), 200, transforms.ToTensor())
+        val_dataset = datasets.FakeData(50000, (3, 64, 64), 200, transforms.ToTensor())
     else:
         traindir = os.path.join(args.data, 'train')
-        valdir = os.path.join(args.data, 'val')
-        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
-                                     std=[0.229, 0.224, 0.225])
+        valdir = os.path.join(args.data, 'val_reorg')
+
+        mean = [0.4802, 0.4481, 0.3975]
+        std = [0.2302, 0.2265, 0.2262]
+
+        train_transforms = transforms.Compose([
+            transforms.ToTensor(),
+            transforms.Normalize(mean, std)
+        ])
+
+        val_transforms = transforms.Compose([
+            transforms.ToTensor(),
+            transforms.Normalize(mean, std)
+        ])
 
         train_dataset = datasets.ImageFolder(
             traindir,
-            transforms.Compose([
-                transforms.RandomResizedCrop(224),
-                transforms.RandomHorizontalFlip(),
-                transforms.ToTensor(),
-                normalize,
-            ]))
+            transform=train_transforms
+        )
 
         val_dataset = datasets.ImageFolder(
             valdir,
-            transforms.Compose([
-                transforms.Resize(256),
-                transforms.CenterCrop(224),
-                transforms.ToTensor(),
-                normalize,
-            ]))
+            transform=val_transforms
+        )
 
     if args.distributed:
         train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)
@@ -266,19 +278,30 @@ def main_worker(gpu, ngpus_per_node, args):
         val_dataset, batch_size=args.batch_size, shuffle=False,
         num_workers=args.workers, pin_memory=True, sampler=val_sampler)
 
+    #Tensorboard
+    writer = SummaryWriter('output3/log')
+
+    #visualize the model
+    #dataiter = iter(trainloader)
+    #images, labels = dataiter.next()
+    
+    #writer.add_graph(model, images)
+    #writer.flush()
+
     if args.evaluate:
-        validate(val_loader, model, criterion, args)
+        validate(val_loader, model, criterion, args, writer, 0)
         return
+    
 
     for epoch in range(args.start_epoch, args.epochs):
         if args.distributed:
             train_sampler.set_epoch(epoch)
 
         # train for one epoch
-        train(train_loader, model, criterion, optimizer, epoch, device, args)
+        train(train_loader, model, criterion, optimizer, epoch, device, args, writer)
 
         # evaluate on validation set
-        acc1 = validate(val_loader, model, criterion, args)
+        acc1 = validate(val_loader, model, criterion, args, writer, epoch)
         
         scheduler.step()
         
@@ -297,8 +320,9 @@ def main_worker(gpu, ngpus_per_node, args):
                 'scheduler' : scheduler.state_dict()
             }, is_best)
 
+    writer.close()
 
-def train(train_loader, model, criterion, optimizer, epoch, device, args):
+def train(train_loader, model, criterion, optimizer, epoch, device, args, writer):
     batch_time = AverageMeter('Time', ':6.3f')
     data_time = AverageMeter('Data', ':6.3f')
     losses = AverageMeter('Loss', ':.4e')
@@ -342,11 +366,21 @@ def train(train_loader, model, criterion, optimizer, epoch, device, args):
 
         if i % args.print_freq == 0:
             progress.display(i + 1)
+        
+        # ...log the running loss
+        writer.add_scalar('training loss',
+                        losses.val,
+                        epoch * len(train_loader) + i)
 
+        writer.add_scalar('training accuracy',
+                        top5.val,
+                        epoch * len(train_loader) + i)
 
-def validate(val_loader, model, criterion, args):
 
+def validate(val_loader, model, criterion, args, writer, epoch):
     def run_validate(loader, base_progress=0):
+        # Add a counter for the number of images logged
+        logged_images = 0
         with torch.no_grad():
             end = time.time()
             for i, (images, target) in enumerate(loader):
@@ -376,6 +410,34 @@ def validate(val_loader, model, criterion, args):
                 if i % args.print_freq == 0:
                     progress.display(i + 1)
 
+                # ...log the running loss
+                writer.add_scalar('validate loss',
+                                losses.val,
+                                epoch * len(loader) + i)
+
+                writer.add_scalar('validate accuracy',
+                                top5.val,
+                                epoch * len(loader) + i)
+                if args.evaluate:
+                    # Log images with different output and target in TensorBoard
+                    if logged_images < 10:
+                        _, pred = torch.max(output, 1)
+                        for j in range(images.size(0)):
+                            if pred[j] != target[j]:
+                                writer.add_image(f'validate/diff_output_target_{logged_images}',
+                                                images[j].cpu().numpy(),
+                                                epoch * len(loader) + i,
+                                                dataformats='CHW')
+                                writer.add_text(f'validate/diff_output_target_{logged_images}/output',
+                                            f'Output: {pred[j]}',
+                                            epoch * len(loader) + i)
+                                writer.add_text(f'validate/diff_output_target_{logged_images}/target',
+                                                f'Target: {target[j]}',
+                                                epoch * len(loader) + i)
+                                logged_images += 1
+                                if logged_images >= 10:
+                                    break
+
     batch_time = AverageMeter('Time', ':6.3f', Summary.NONE)
     losses = AverageMeter('Loss', ':.4e', Summary.NONE)
     top1 = AverageMeter('Acc@1', ':6.2f', Summary.AVERAGE)
@@ -406,10 +468,10 @@ def validate(val_loader, model, criterion, args):
     return top1.avg
 
 
-def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):
+def save_checkpoint(state, is_best, filename='/output/checkpoint.pth.tar'):
     torch.save(state, filename)
-    if is_best:
-        shutil.copyfile(filename, 'model_best.pth.tar')
+    #if is_best:
+        #shutil.copyfile(filename, '/output/model_best.pth.tar')
 
 class Summary(Enum):
     NONE = 0
